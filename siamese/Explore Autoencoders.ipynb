{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy.spatial.distance\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\elec_ind_to_sents.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-202-0028d45d118f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0midx_to_sents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"elec_ind_to_sents.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprod_to_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"prod_to_ind.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\elec_ind_to_sents.pkl'"
     ]
    }
   ],
   "source": [
    "idx_to_sents = pickle.load(open(os.path.join(\"data\", \"elec_ind_to_sents.pkl\"), 'rb'))\n",
    "prod_to_idx = pickle.load(open(os.path.join(\"data\", \"prod_to_ind.pkl\"), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pairs = pd.read_csv(os.path.join(\"..\", \"src\", \"data\", \"paired_sentences.csv\"), sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>works fine, as expected</td>\n",
       "      <td>Works great and cannot  beat the price!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>works fine, as expected</td>\n",
       "      <td>Worked very good for what i needed and the pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Works, great, shipped fast, great price.</td>\n",
       "      <td>This cable works perfectly and at a great price!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This cable is awesome and does the required jo...</td>\n",
       "      <td>Excellent product, no complains, good price, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So far it is working great.</td>\n",
       "      <td>So far this item is great.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Works like a charm.</td>\n",
       "      <td>Work very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This is a great SD card, it is very fast and w...</td>\n",
       "      <td>This is a class 10 microSD card, and it works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>No problems with it.</td>\n",
       "      <td>Quick response, no lag or compatibility issues.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nothing really to say, except for excellent me...</td>\n",
       "      <td>Holds lots of data with fast read/write capabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This is a class 10 microSD card, and it works ...</td>\n",
       "      <td>This is a great SD card, it is very fast and w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I have got a couple of these in varying sizes.</td>\n",
       "      <td>Available in sizes up to 64GB, it can store al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shipping was excellent fast and reliable.</td>\n",
       "      <td>Shipping was fast, too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The result was that on average, SanDisk's card...</td>\n",
       "      <td>Drops were as low as 7MB/s.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>San-disk is a pretty reliable brand as you wil...</td>\n",
       "      <td>I have found the SanDisk brand to be dependable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>It is tiny enough for me to have misplaced it ...</td>\n",
       "      <td>That made this a bad choice for me because it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>So when it comes to flash drives, small is not...</td>\n",
       "      <td>it is hard to remove from the port when needed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Its black color also provides such good camouf...</td>\n",
       "      <td>It is also dark in color, so not that easy  to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cannot upload large size files due to flash dr...</td>\n",
       "      <td>Files over 4 GB will not be accepted, you will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Also after a couple months of being in my pock...</td>\n",
       "      <td>So do not rely on that keychain to hold it, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'This flash drive does have a very small yello...</td>\n",
       "      <td>'Small and effective, actually has a light to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text1  \\\n",
       "0                            works fine, as expected    \n",
       "1                            works fine, as expected    \n",
       "2            Works, great, shipped fast, great price.   \n",
       "3   This cable is awesome and does the required jo...   \n",
       "4                         So far it is working great.   \n",
       "5                                Works like a charm.    \n",
       "6   This is a great SD card, it is very fast and w...   \n",
       "7                                No problems with it.   \n",
       "8   Nothing really to say, except for excellent me...   \n",
       "9   This is a class 10 microSD card, and it works ...   \n",
       "10     I have got a couple of these in varying sizes.   \n",
       "11          Shipping was excellent fast and reliable.   \n",
       "12  The result was that on average, SanDisk's card...   \n",
       "13  San-disk is a pretty reliable brand as you wil...   \n",
       "14  It is tiny enough for me to have misplaced it ...   \n",
       "15  So when it comes to flash drives, small is not...   \n",
       "16  Its black color also provides such good camouf...   \n",
       "17  Cannot upload large size files due to flash dr...   \n",
       "18  Also after a couple months of being in my pock...   \n",
       "19  'This flash drive does have a very small yello...   \n",
       "\n",
       "                                                text2  \n",
       "0             Works great and cannot  beat the price!  \n",
       "1   Worked very good for what i needed and the pri...  \n",
       "2    This cable works perfectly and at a great price!  \n",
       "3   Excellent product, no complains, good price, w...  \n",
       "4                          So far this item is great.  \n",
       "5                                      Work very good  \n",
       "6   This is a class 10 microSD card, and it works ...  \n",
       "7     Quick response, no lag or compatibility issues.  \n",
       "8   Holds lots of data with fast read/write capabi...  \n",
       "9   This is a great SD card, it is very fast and w...  \n",
       "10  Available in sizes up to 64GB, it can store al...  \n",
       "11                            Shipping was fast, too.  \n",
       "12                        Drops were as low as 7MB/s.  \n",
       "13   I have found the SanDisk brand to be dependable.  \n",
       "14  That made this a bad choice for me because it ...  \n",
       "15    it is hard to remove from the port when needed.  \n",
       "16  It is also dark in color, so not that easy  to...  \n",
       "17  Files over 4 GB will not be accepted, you will...  \n",
       "18  So do not rely on that keychain to hold it, bu...  \n",
       "19  'Small and effective, actually has a light to ...  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = torch.load(\"src_vocab.pt\")\n",
    "trg_vocab = torch.load(\"trg_vocab.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trad. Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"electronics_autoencoder_epoch7.pt\"\n",
    "autoencoder = torch.load(model_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Siamese Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model_path = \"siamese_ae_epoch_1\"\n",
    "siamese_autoencoder = torch.load(siamese_model_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed & Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = len(sentence_pairs)\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenNMT: Open-Source Toolkit for Neural Machine Translation\n",
    "# https://github.com/harvardnlp/annotated-transformer\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    #print(src.shape)\n",
    "    memory = model.encode(src, src_mask)[0:1, :, :]\n",
    "    #print(memory.shape)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decode(memory, src_mask, \n",
    "                           Variable(ys), \n",
    "                           Variable(subsequent_mask(ys.size(1))\n",
    "                                    .type_as(src.data)))\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat([ys, \n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "    #print(len(ys))\n",
    "    return memory, ys\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0\n",
    "\n",
    "# src is a list of indices\n",
    "def generate_sentence(model, src):\n",
    "    embedding, decode_idx = greedy_decode(model, src, Variable(torch.ones(1, 1, src.shape[1])),\n",
    "                                          src.shape[1], start_symbol=trg_vocab.stoi[\"<s>\"])\n",
    "    \n",
    "    return embedding.detach().numpy()[0, 0:1, :], \" \".join([trg_vocab.itos[idx] for idx in decode_idx[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_idx = []\n",
    "for s in list(sentence_pairs['text1']):\n",
    "    text1_idx.append(torch.LongTensor([[src_vocab.stoi['<cls>']] + [src_vocab.stoi[word] for word in s.lower().split()]]))\n",
    "    \n",
    "text2_idx = []\n",
    "for s in list(sentence_pairs['text2']):\n",
    "    text2_idx.append(torch.LongTensor([[src_vocab.stoi['<cls>']] + [src_vocab.stoi[word] for word in s.lower().split()]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_em1 = np.zeros((NUM_EXAMPLES, EMBEDDING_DIM))\n",
    "ae_em2 = np.zeros((NUM_EXAMPLES, EMBEDDING_DIM))\n",
    "ae_text1 = [\"\"] * NUM_EXAMPLES \n",
    "ae_text2 = [\"\"] * NUM_EXAMPLES \n",
    "\n",
    "sae_em1 = np.zeros((NUM_EXAMPLES, EMBEDDING_DIM))\n",
    "sae_em2 = np.zeros((NUM_EXAMPLES, EMBEDDING_DIM))\n",
    "sae_text1 = [\"\"] * NUM_EXAMPLES \n",
    "sae_text2 = [\"\"] * NUM_EXAMPLES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (sent1, sent2) in enumerate(zip(text1_idx, text2_idx)):\n",
    "    ae_em1[i, :], ae_text1[i] = generate_sentence(autoencoder, sent1)\n",
    "    ae_em2[i, :], ae_text2[i] = generate_sentence(autoencoder, sent2)\n",
    "    \n",
    "    sae_em1[i, :], sae_text1[i] = generate_sentence(siamese_autoencoder, sent1)\n",
    "    sae_em2[i, :], sae_text2[i] = generate_sentence(siamese_autoencoder, sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_generations = pd.DataFrame(data={\"text1\" : ae_text1,\n",
    "                                    \"text2\" : ae_text2})\n",
    "sae_generations = pd.DataFrame(data={\"text1\" : sae_text1,\n",
    "                                     \"text2\" : sae_text2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05975877050345324,\n",
       " 0.07046368342948561,\n",
       " 0.0459657557622174,\n",
       " 0.06984496421789355,\n",
       " 0.050298685320323444,\n",
       " 0.0473509475663324,\n",
       " 0.05905873002209139,\n",
       " 0.07520556659799649,\n",
       " 0.04495040340761092,\n",
       " 0.06859156281609291,\n",
       " 0.05226503200430921,\n",
       " 0.0474738738549465,\n",
       " 0.05144096937983178,\n",
       " 0.060098714580836265,\n",
       " 0.05847989056459124,\n",
       " 0.06296672660220604,\n",
       " 0.052545018244673836,\n",
       " 0.06444811661341143,\n",
       " 0.048711909384371754,\n",
       " 0.05625952098941511]"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare embeddings\n",
    "embed_diff = np.linalg.norm(ae_em1 - sae_em1, axis = 1)\n",
    "cosine_dist = [scipy.spatial.distance.cosine(ae_em1[row_idx], sae_em1[row_idx]) for row_idx in range(ae_em1.shape[0])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth:\n",
      "0    works fine, as expected \n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "0    <s> works <unk> as expected\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "0    <s> works <unk> as expected\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "1    works fine, as expected \n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "1    <s> works <unk> as expected\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "1    <s> works <unk> as expected\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "2    Works, great, shipped fast, great price.\n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "2    <s> <unk> shipped <unk> great <unk> </s>\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "2    <s> <unk> shipped <unk> <unk> great </s>\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "3    This cable is awesome and does the required jo...\n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "3    <s> this cable is awesome and does the require...\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "3    <s> this cable is awesome and does the require...\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "4    So far it is working great.\n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "4    <s> so far it is working <unk>\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "4    <s> so far it is working <unk>\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "5    Works like a charm. \n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "5    <s> works like a <unk>\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "5    <s> works like a <unk>\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "6    This is a great SD card, it is very fast and w...\n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "6    <s> this is a great sd <unk> it is very fast a...\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "6    <s> this is a great sd <unk> it is very fast a...\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "7    No problems with it.\n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "7    <s> no problems with <unk>\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "7    <s> no problems with <unk>\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "8    Nothing really to say, except for excellent me...\n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "8    <s> nothing really to <unk> except for excelle...\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "8    <s> nothing really to <unk> except for excelle...\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "9    This is a class 10 microSD card, and it works ...\n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "9    <s> this is a class 10 microsd <unk> and it wo...\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "9    <s> this is a class 10 microsd <unk> and it wo...\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "10    I have got a couple of these in varying sizes.\n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "10    <s> i have got a couple of these in varying <unk>\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "10    <s> i have got a couple of these in varying <unk>\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "11    Shipping was excellent fast and reliable.\n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "11    <s> shipping was excellent fast and <unk>\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "11    <s> shipping was excellent fast and <unk>\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "12    The result was that on average, SanDisk's card...\n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "12    <s> the result was that on <unk> card would ma...\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "12    <s> the result was that on <unk> <unk> card wo...\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "13    San-disk is a pretty reliable brand as you wil...\n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "13    <s> <unk> is a pretty reliable brand as you wi...\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "13    <s> <unk> is a pretty reliable brand as you wi...\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "14    It is tiny enough for me to have misplaced it ...\n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "14    <s> it is tiny enough for me to have misplaced...\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "14    <s> it is tiny enough for me to have misplaced...\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "15    So when it comes to flash drives, small is not...\n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "15    <s> so when it comes to flash small <unk> is n...\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "15    <s> so when it comes to flash <unk> small is n...\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "16    Its black color also provides such good camouf...\n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "16    <s> this black also provides excellent color i...\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "16    <s> its also black light such provides good co...\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "17    Cannot upload large size files due to flash dr...\n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "17    <s> cannot upload large size files due to flas...\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "17    <s> cannot upload large size files due to flas...\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "18    Also after a couple months of being in my pock...\n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "18    <s> also after a couple months of being in my ...\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "18    <s> also after being a couple of months in the...\n",
      "Name: text1, dtype: object\n",
      "Ground Truth:\n",
      "19    'This flash drive does have a very small yello...\n",
      "Name: text1, dtype: object\n",
      "Traditional Autoencoder:\n",
      "19    <s> <unk> flash drive does have a very small <...\n",
      "Name: text1, dtype: object\n",
      "Siamese Autoencoder:\n",
      "19    <s> <unk> flash drive does have a very small <...\n",
      "Name: text1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# compare generated sentences\n",
    "for i, sent in enumerate(text1_idx):\n",
    "    print(\"Ground Truth:\")\n",
    "    print(sentence_pairs.iloc[[i]][\"text1\"])\n",
    "    print(\"Traditional Autoencoder:\")\n",
    "    print(ae_generations.iloc[[i]][\"text1\"])\n",
    "    print(\"Siamese Autoencoder:\")\n",
    "    print(sae_generations.iloc[[i]][\"text1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> works <unk> as expected'"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_generations.head()[\"text1\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> although i did a reset and put the information back it , still it was only about 1/2 the wired speed .'"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#t1 = \"<cls> my name is mouse\"\n",
    "t1 = \"<cls> although i did a reset and put the information back it , it still was only about 1/2 the wired speed .\"\n",
    "generate_sentence(autoencoder, torch.LongTensor([[src_vocab.stoi[word] for word in t1.split(\" \")]]))[1]\n",
    "#a = torch.LongTensor([[vocab.vocab.stoi[\"works\"], vocab.vocab.stoi[\"works\"]]])\n",
    "#len(a)\n",
    "#vocab.vocab.stoi[\"works\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> although i did a reset and put the information back it , it still was only about 1/2 the load speed .'"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"<cls> although i did a reset and put the information back it , it still was only about 1/2 the wired speed .\"\n",
    "generate_sentence(siamese_autoencoder, torch.LongTensor([[src_vocab.stoi[word] for word in sent.split(\" \")]]))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.327527  , -0.07893595, -0.03025211,  0.06831298, -0.04272245,\n",
       "         0.3032343 , -0.05806926,  0.17110014,  0.23537478,  0.31595305,\n",
       "         0.2501623 , -0.1290037 , -0.4187692 , -0.12036887, -0.17526104,\n",
       "         0.09711945,  0.13879128, -0.23180503, -0.5544039 ,  0.2852068 ,\n",
       "         0.13227893,  0.32887796, -0.07234141,  0.35504264, -0.12981115,\n",
       "        -0.09143321,  0.25975046, -0.00717225,  0.23184444,  0.02577189,\n",
       "         0.10984887, -0.24008559, -0.23390111,  0.07360381,  0.33547848,\n",
       "        -0.38813397, -0.01689984,  0.15639558, -0.165597  ,  0.37081578,\n",
       "        -0.03423387,  0.23196715, -0.04946449,  0.06075588, -0.03328081,\n",
       "        -0.21012552,  0.02266237,  0.13535114,  0.15985373, -0.0694741 ,\n",
       "         0.00838902, -0.17869434,  0.04301745, -0.15593764, -0.01497189,\n",
       "         0.53302747,  0.45639804,  0.08358166, -0.21247894, -0.0152492 ,\n",
       "        -0.42844784,  0.20368141,  0.32746452, -0.04071741, -0.26871657,\n",
       "         0.0035231 , -0.36912322, -0.47927547, -0.25796527, -0.15372196,\n",
       "         0.16163793,  0.04808627, -0.05703148,  0.14982714,  0.03917009,\n",
       "        -0.10467625, -0.10268477, -0.19609985,  0.19979791, -0.15798716,\n",
       "        -0.0626866 , -0.18328938,  0.01852467,  0.43623227,  0.06348073,\n",
       "         0.07471585, -0.43149355,  0.23262568,  0.23827857,  0.07056105,\n",
       "        -0.24139707,  0.24411036,  0.10884801,  0.12408787, -0.21799415,\n",
       "        -0.36337578, -0.05234919, -0.10355578,  0.1735956 , -0.2683188 ,\n",
       "         0.06049711,  0.09605456, -0.02375908, -0.16070522,  0.10697519,\n",
       "         0.2289921 ,  0.12063726, -0.16564953, -0.02972673,  0.08824813,\n",
       "         0.09473478,  0.15466912,  0.12777606,  0.30371   , -0.01119643,\n",
       "         0.26238862,  0.2568066 , -0.21502356, -0.11034818,  0.11349244,\n",
       "         0.40943384, -0.01287309,  0.24709783, -0.24139899, -0.25615087,\n",
       "        -0.00631984,  0.04825504, -0.04686439,  0.15473104, -0.34880725,\n",
       "        -0.05537781, -0.11204585, -0.09257509, -0.0036383 ,  0.24964869,\n",
       "         0.00201686,  0.07632187,  0.29778183,  0.15778925, -0.3414365 ,\n",
       "        -0.4640174 , -0.17396063, -0.3789322 ,  0.35007897, -0.02233151,\n",
       "         0.07968142, -0.2986338 , -0.22359675, -0.07918146,  0.03167985,\n",
       "         0.00369188, -0.2493622 ,  0.12620999,  0.30664802, -0.15840225,\n",
       "         0.28035292, -0.10321511,  0.00410578, -0.31823534, -0.11507887,\n",
       "         0.06566736,  0.0301376 , -0.04320457,  0.02975275, -0.16268173,\n",
       "        -0.09983697, -0.00860865, -0.5219656 ,  0.25416186,  0.19247916,\n",
       "         0.12242957, -0.20210157, -0.06631191,  0.31511605,  0.01575501,\n",
       "        -0.07131777,  0.13637134, -0.10350518, -0.05985465, -0.13581243,\n",
       "        -0.15846442,  0.35536608,  0.2660144 ,  0.02039872,  0.00490191,\n",
       "        -0.18677992,  0.46620598,  0.00895534,  0.01025804, -0.14412141,\n",
       "        -0.2583087 , -0.16396762,  0.08319689, -0.07079874, -0.09961586,\n",
       "         0.03455206, -0.13873458,  0.068749  ,  0.252942  , -0.21667977,\n",
       "        -0.37907326,  0.3631998 , -0.29814452,  0.03211277,  0.1800206 ,\n",
       "        -0.00360396, -0.18680881,  0.48250818,  0.06872702, -0.05666286,\n",
       "        -0.2989493 ,  0.07097834, -0.1988119 ,  0.04534747,  0.02956414,\n",
       "        -0.02749566,  0.02399973, -0.23069128,  0.1096383 , -0.13815434,\n",
       "         0.01742752,  0.00246957, -0.12316957,  0.04780729,  0.27991405,\n",
       "         0.0684351 , -0.24352741,  0.28341538, -0.15139326, -0.24019878,\n",
       "        -0.07533597,  0.05917811,  0.2903162 ,  0.01317332, -0.3068242 ,\n",
       "         0.06218488, -0.2544521 ,  0.0144617 ,  0.06395761, -0.10714143,\n",
       "        -0.15368749,  0.22175138,  0.13490939,  0.28434986, -0.24327886,\n",
       "        -0.13268311, -0.3204721 , -0.09931426,  0.4121566 ,  0.29565394,\n",
       "         0.11464572, -0.08925163, -0.16900258, -0.03946535, -0.10365485,\n",
       "        -0.08161369,  0.16421299, -0.01892562,  0.21883763,  0.0300328 ,\n",
       "        -0.1633321 , -0.01099136,  0.02267581,  0.09493973, -0.1648332 ,\n",
       "         0.03047844,  0.0081228 ,  0.06156126, -0.12486817, -0.19384557,\n",
       "         0.03722274, -0.17505357, -0.18469995,  0.19464514,  0.09478348,\n",
       "         0.533623  , -0.24101704, -0.05920567, -0.01408495, -0.11966162,\n",
       "        -0.41202617,  0.20745951,  0.09260932, -0.17075472, -0.08452298,\n",
       "        -0.1612625 , -0.11990835, -0.11937687,  0.11005875,  0.26734206,\n",
       "         0.08857311,  0.19858104,  0.03854287, -0.24031064,  0.02460648,\n",
       "        -0.1316012 ,  0.42245167,  0.01094904,  0.01859515, -0.19544867]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sent = \" <s> i am sure it would be great for tvs , unfortunately , it did not provide what i was looking for . \"\n",
    "#sent = \"<s> works .\"\n",
    "generate_sentence(siamese_autoencoder, torch.LongTensor([[src_vocab.stoi[word] for word in sent.split(\" \")]]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06696489, -0.01360267, -0.11010815, -0.06046246, -0.01499155,\n",
       "         0.13420883, -0.0139626 , -0.07353418,  0.02505079, -0.04594058,\n",
       "        -0.04192559, -0.01561375, -0.04797715,  0.03600286,  0.00644682,\n",
       "        -0.0350748 , -0.01240247,  0.02584046, -0.06989545,  0.08013795,\n",
       "        -0.00676228,  0.1262049 ,  0.01782373, -0.14406513, -0.03961991,\n",
       "         0.01467997, -0.08886129, -0.03374509, -0.04057646,  0.03435272,\n",
       "        -0.01613023, -0.03020197,  0.0252299 , -0.04335134,  0.10916996,\n",
       "        -0.05861974, -0.06997047, -0.02427427,  0.0672856 , -0.01678962,\n",
       "         0.00091328, -0.07406348,  0.07543211, -0.12470326, -0.09766726,\n",
       "        -0.07078223,  0.04226875,  0.02764156,  0.03387237, -0.03993648,\n",
       "        -0.06418075, -0.13136077,  0.05601442, -0.01439732,  0.01550303,\n",
       "         0.04695272,  0.00230411, -0.0363141 , -0.0106689 ,  0.01355925,\n",
       "        -0.12594956,  0.06793629, -0.02647994, -0.04592808, -0.15866584,\n",
       "        -0.04514493, -0.14673346,  0.00191793, -0.00587226, -0.08866878,\n",
       "         0.00125273, -0.01604846,  0.01897794,  0.05307528,  0.02314801,\n",
       "        -0.0154751 , -0.07247459,  0.09918338,  0.03330336, -0.09957735,\n",
       "         0.01160406, -0.1428211 ,  0.01253218, -0.04978627, -0.0632759 ,\n",
       "        -0.05144924, -0.04562044,  0.07143405,  0.06184512, -0.02231681,\n",
       "         0.04205066,  0.12905556, -0.01154564,  0.05466935,  0.03615069,\n",
       "        -0.03503349,  0.06053533, -0.01671616, -0.16782486,  0.02198055,\n",
       "        -0.04083579, -0.00256833,  0.01545988,  0.01345801, -0.02818898,\n",
       "        -0.09342335,  0.02897273, -0.10535359,  0.08923745, -0.02092105,\n",
       "        -0.07151322,  0.00427589,  0.05531671,  0.09029654, -0.12854216,\n",
       "         0.03162464,  0.04009442,  0.05936286,  0.00960097, -0.0632676 ,\n",
       "         0.0397633 , -0.03349962,  0.08885175,  0.15988499, -0.03163777,\n",
       "        -0.08681982,  0.04251507, -0.10861248,  0.03951317,  0.01420155,\n",
       "         0.05617908,  0.06004231,  0.16001014,  0.06725258,  0.02083994,\n",
       "         0.01723906,  0.03381829,  0.05173513,  0.07470265,  0.01211905,\n",
       "         0.04596227, -0.01555766, -0.03839111, -0.15816581, -0.0168477 ,\n",
       "         0.08802939,  0.15739332, -0.00263074,  0.02379103,  0.00935946,\n",
       "         0.11780592, -0.01697075, -0.02575396,  0.10905367, -0.09230291,\n",
       "        -0.01855385,  0.07989226,  0.0990303 ,  0.02475695,  0.02784021,\n",
       "        -0.00260308, -0.05325666,  0.13899404, -0.07122372,  0.08250624,\n",
       "        -0.02455651, -0.03182227,  0.06394362, -0.02502488, -0.027467  ,\n",
       "        -0.0691236 , -0.01375288,  0.09715958,  0.07675014,  0.03295221,\n",
       "        -0.07780176,  0.0470388 ,  0.00570641, -0.06379012,  0.00980967,\n",
       "         0.07803404,  0.0561842 , -0.10561629,  0.08910909,  0.05562056,\n",
       "         0.05343634,  0.15881416, -0.02318817,  0.01458451, -0.0823899 ,\n",
       "         0.05410723, -0.0051631 ,  0.02264066,  0.05156177, -0.0132128 ,\n",
       "         0.04497591, -0.03119079,  0.09499727,  0.02321896,  0.01086598,\n",
       "        -0.24576575,  0.09640431,  0.00970641, -0.05541116, -0.05170228,\n",
       "         0.0335466 ,  0.00792962,  0.15380618,  0.10671373, -0.02830502,\n",
       "         0.033591  ,  0.07095723,  0.07899281, -0.10568998,  0.08295044,\n",
       "         0.05926508,  0.12272693, -0.03229253, -0.02712551,  0.04016849,\n",
       "        -0.01412663, -0.12910792,  0.00893648,  0.00232546,  0.08379498,\n",
       "         0.04668451,  0.00437325, -0.05582222, -0.00490847, -0.04142416,\n",
       "         0.00175994,  0.02854549, -0.02299815, -0.09226764, -0.06990758,\n",
       "        -0.04152011, -0.03798038, -0.08714867, -0.02791736, -0.00598509,\n",
       "        -0.00949874,  0.08396307, -0.00968471,  0.09962866,  0.02022293,\n",
       "         0.06073035, -0.12416726, -0.01499572,  0.04574522,  0.04209284,\n",
       "        -0.02026623,  0.0234558 , -0.04504165,  0.03140906, -0.00987425,\n",
       "        -0.04641658, -0.11392212, -0.05765544, -0.04077269, -0.02970144,\n",
       "         0.02554996,  0.06083155,  0.0670132 , -0.03938913,  0.00552101,\n",
       "         0.05636257, -0.01540379,  0.02978177,  0.00811237,  0.0180601 ,\n",
       "        -0.10806894, -0.03367874,  0.10901967, -0.04532391,  0.07545482,\n",
       "         0.12974846, -0.09286058,  0.04631299, -0.05090515,  0.07680663,\n",
       "        -0.01353514,  0.13326354,  0.10681921,  0.04114126, -0.02355489,\n",
       "         0.037644  ,  0.059521  , -0.10189171, -0.03893236,  0.05985682,\n",
       "        -0.00552972, -0.11642625,  0.0780493 , -0.03493054, -0.08991705,\n",
       "        -0.04629325,  0.09917089, -0.07658361,  0.03268264, -0.09684838]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(siamese_autoencoder, torch.LongTensor([[src_vocab.stoi[word] for word in sent.split(\" \")]]))[0] - generate_sentence(autoencoder, torch.LongTensor([[src_vocab.stoi[word] for word in sent.split(\" \")]]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# - How much to embeddings change (euclidean distance, cosine distance)\n",
    "# - How much do sentences differ (n-gram overlap {1,2}) --> should be low\n",
    "# - If we cluster these vectors (using K-Means or DBSCAN):\n",
    "#   - Are sentences placed in different clusters (is there a signficant effect, does it depend on the hyper param.)\n",
    "#   - Are clusters more semantically integrated (using WordNet, \n",
    "#                                                How BOW / Word2Vec is clustered --> more diagnostic, \n",
    "#                                                topic modelling on random permutations of the sentences in cluster,\n",
    "#                                                jaccard similarity\n",
    "#                                               )\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "# Jaccard Similarity, Average of vectors for sentences as a metric(to see how close it is to clustering by Word2vec)\n",
    "# Semantic Ontologies\n",
    "# Experiments: how are paired vectors placed compared to each other"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
